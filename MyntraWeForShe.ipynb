{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0gIdo1pPArjW",
        "outputId": "310875ef-dec4-496a-e210-c56a4e01568d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.31)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (2.9.9)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy pandas nltk sqlalchemy psycopg2-binary flask schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOE4pFh-Azhd",
        "outputId": "18460977-bd9c-4262-ab53-a6222563920c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration file created.\n"
          ]
        }
      ],
      "source": [
        "# Configuration setup\n",
        "from configparser import ConfigParser\n",
        "\n",
        "config = ConfigParser()\n",
        "\n",
        "config['twitter'] = {\n",
        "    'consumer_key': '',\n",
        "    'consumer_secret': '',\n",
        "    'access_token': '',\n",
        "    'access_token_secret': ''\n",
        "}\n",
        "\n",
        "with open('/content/config.ini', 'w') as configfile:\n",
        "    config.write(configfile)\n",
        "\n",
        "print(\"Configuration file created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjTDqA94BMd8",
        "outputId": "768ee377-e193-4589-baba-7a95d31665bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "<ipython-input-4-f9ba7e3353a3>:34: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulated tweets collected and stored.\n",
            "Fashion Trend Report:\n",
            "Top Words: [('brand', 78), ('designer', 75), ('glamour', 75), ('style', 73), ('vogue', 73), ('outfit', 72), ('runway', 71), ('luxury', 69), ('couture', 69), ('accessories', 68)]\n",
            "Top Hashtags: [('#style', 43), ('#luxury', 42), ('#vogue', 41), ('#outfit', 40), ('#glamour', 38), ('#brand', 38), ('#clothes', 37), ('#couture', 36), ('#runway', 35), ('#chic', 35)]\n",
            "Sentiment Distribution: {'neutral': 0.7575, 'positive': 0.2425}\n"
          ]
        }
      ],
      "source": [
        "#libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import re\n",
        "from sqlalchemy import create_engine, Column, Integer, String, DateTime, Float\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from flask import Flask, jsonify\n",
        "import configparser\n",
        "import schedule\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "#NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "\n",
        "config['database'] = {\n",
        "    'connection_string': ''\n",
        "}\n",
        "\n",
        "with open('/content/config.ini', 'w') as configfile:\n",
        "    config.write(configfile)\n",
        "\n",
        "config.read('/content/config.ini')\n",
        "\n",
        "Base = declarative_base()\n",
        "\n",
        "class FashionTweet(Base):\n",
        "    __tablename__ = 'fashion_tweets'\n",
        "\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    text = Column(String)\n",
        "    clean_text = Column(String)\n",
        "    user = Column(String)\n",
        "    created_at = Column(DateTime)\n",
        "    hashtags = Column(String)\n",
        "    sentiment = Column(Float)\n",
        "\n",
        "engine = create_engine(config['database']['connection_string'])\n",
        "Base.metadata.create_all(engine)\n",
        "Session = sessionmaker(bind=engine)\n",
        "\n",
        "fashion_keywords = ['fashion', 'style', 'trend', 'outfit', 'clothes', 'wear', 'dress', 'shoes', 'accessories',\n",
        "                    'designer', 'collection', 'runway', 'model', 'brand', 'luxury', 'vintage', 'sustainable',\n",
        "                    'couture', 'vogue', 'chic', 'elegant', 'glamour', 'fashionweek', 'streetwear']\n",
        "fashion_influencers = ['vogue', 'elle', 'harpersbazaar', 'wmag', 'instyle']\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s#]', '', text)\n",
        "    return text.lower()\n",
        "\n",
        "def extract_hashtags(text):\n",
        "    return [word for word in text.split() if word.startswith('#')]\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    return sia.polarity_scores(text)['compound']\n",
        "\n",
        "def generate_simulated_tweet():\n",
        "    text = f\"Check out this {random.choice(fashion_keywords)} {random.choice(fashion_keywords)}! #{random.choice(fashion_keywords)} #{random.choice(fashion_keywords)}\"\n",
        "    clean_text_content = clean_text(text)\n",
        "    hashtags = extract_hashtags(clean_text_content)\n",
        "    sentiment = analyze_sentiment(clean_text_content)\n",
        "\n",
        "    return FashionTweet(\n",
        "        text=text,\n",
        "        clean_text=clean_text_content,\n",
        "        user=random.choice(fashion_influencers),\n",
        "        created_at=datetime.now() - timedelta(minutes=random.randint(0, 60)),\n",
        "        hashtags=','.join(hashtags),\n",
        "        sentiment=sentiment\n",
        "    )\n",
        "\n",
        "def collect_simulated_tweets():\n",
        "    session = Session()\n",
        "    for _ in range(200): #200 tweets at a time\n",
        "        tweet = generate_simulated_tweet()\n",
        "        session.add(tweet)\n",
        "\n",
        "    session.commit()\n",
        "    session.close()\n",
        "    print(\"Simulated tweets collected and stored.\")\n",
        "\n",
        "def analyze_trends():\n",
        "    session = Session()\n",
        "    tweets = session.query(FashionTweet).order_by(FashionTweet.created_at.desc()).limit(1000).all()\n",
        "\n",
        "    word_freq = Counter()\n",
        "    hashtag_freq = Counter()\n",
        "\n",
        "    for tweet in tweets:\n",
        "        words = word_tokenize(tweet.clean_text)\n",
        "        word_freq.update([w for w in words if w in fashion_keywords])\n",
        "        hashtag_freq.update(tweet.hashtags.split(','))\n",
        "\n",
        "    top_words = word_freq.most_common(10)\n",
        "    top_hashtags = hashtag_freq.most_common(10)\n",
        "\n",
        "    sentiment_dist = pd.Series([tweet.sentiment for tweet in tweets]).apply(lambda x: 'positive' if x > 0 else ('negative' if x < 0 else 'neutral')).value_counts(normalize=True)\n",
        "\n",
        "    session.close()\n",
        "\n",
        "    return {\n",
        "        'top_words': top_words,\n",
        "        'top_hashtags': top_hashtags,\n",
        "        'sentiment_distribution': sentiment_dist.to_dict()\n",
        "    }\n",
        "\n",
        "app = Flask(__name__) #HTTP server to call this model and use it with any required provider or web frontend\n",
        "\n",
        "@app.route('/generate_report', methods=['GET'])\n",
        "def generate_report():\n",
        "    trends = analyze_trends()\n",
        "    return jsonify(trends)\n",
        "\n",
        "def run_collection():\n",
        "    while True:\n",
        "        collect_simulated_tweets()\n",
        "        print(\"Simulated tweets collected and stored.\")\n",
        "        time.sleep(60)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    collect_simulated_tweets()\n",
        "\n",
        "    report = analyze_trends()\n",
        "    print(\"Fashion Trend Report:\")\n",
        "    print(\"Top Words:\", report['top_words'])\n",
        "    print(\"Top Hashtags:\", report['top_hashtags'])\n",
        "    print(\"Sentiment Distribution:\", report['sentiment_distribution'])\n",
        "    # run_collection()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
